{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9632898",
   "metadata": {},
   "source": [
    "# 프로젝트 (1) load_digits : 손글씨 분류\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c1736c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.2\n"
     ]
    }
   ],
   "source": [
    "# 라이브러리 버전확인\n",
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41254637",
   "metadata": {},
   "source": [
    "### (1) 필요한 모듈 import 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d60b450",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22d5edc",
   "metadata": {},
   "source": [
    "### (2) 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "192310f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DESCR', 'data', 'feature_names', 'frame', 'images', 'target', 'target_names']\n"
     ]
    }
   ],
   "source": [
    "# 로드된 digits 데이터셋을 digits라는 변수에 할당\n",
    "digits = load_digits() \n",
    "\n",
    "# digits객체가 어떤 변수와 메서드를 갖는지 나열\n",
    "print(dir(digits))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df9069f",
   "metadata": {},
   "source": [
    "### (3) 데이터 이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7379f902",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋에 담긴 정보 종류 확인\n",
    "digits.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d606d91",
   "metadata": {},
   "source": [
    "1. Feature data 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ae19760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "# key 에서 확인한 정보 중, data를 따로 digits_data 변수에 할당\n",
    "digits_data = digits.data\n",
    "print(digits.data.shape)\n",
    "# 총 1797개의 데이터, 각 데이터는 64개의 숫자로 이루어짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "026a2211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea5527c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(digits.data[0].reshape(8,8), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fed53d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(digits.data[i].reshape(8,8), cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0475edb0",
   "metadata": {},
   "source": [
    "2. Label data 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce78c9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 출력해야 하는 정답인 타겟정보 라벨 변수에 할당\n",
    "digits_label = digits.target\n",
    "print(digits_label.shape)\n",
    "digits_label[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c9c6c1",
   "metadata": {},
   "source": [
    "3. Target Names 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3687e3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 타겟의 이름 확인. 이미지의 숫자에 해당하는 숫자가 표기되어 있음.\n",
    "digits.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcef171",
   "metadata": {},
   "source": [
    "4. 데이터 describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fca5e6df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pixel_0_0', 'pixel_0_1', 'pixel_0_2']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# digits.data에 있는 이미지의 인덱싱이 들어있는 듯 함.\n",
    "digits.feature_names[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3fb32d",
   "metadata": {},
   "source": [
    "### (4) train, test 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f893168f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6638adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# digits_data의 데이터 타입 확인\n",
    "type(digits_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18788a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split이용한 학습데이터와 테스트 데이터 분리\n",
    "# digits_data : 나눌 data (문제지)\n",
    "# digits_label : 데이터의 라벨 (답안지)\n",
    "# test_size : 위 두 항목을 각각 8:2 비율로 잘라서 학습(테스트)데이터의 x, y에 할당\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits_data, digits_label, test_size=0.2, random_state = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6951f996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 개수: 1437 , X_test 개수:  360\n"
     ]
    }
   ],
   "source": [
    "print('X_train 개수:', len(X_train), ', X_test 개수: ', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c37061f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1437, 64), (1437,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train의 형상정보 확인\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ba9581a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((360, 64), (360,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test의 형상정보 확인\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f64e644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6, 4, 3, ..., 8, 8, 6]),\n",
       " array([9, 4, 4, 1, 2, 6, 4, 2, 5, 1, 5, 6, 8, 6, 6, 6, 4, 6, 1, 3, 3, 5,\n",
       "        2, 6, 7, 5, 4, 3, 7, 3, 9, 0, 4, 6, 8, 7, 1, 8, 7, 9, 8, 0, 4, 9,\n",
       "        3, 8, 7, 6, 7, 2, 8, 9, 3, 1, 2, 8, 6, 4, 8, 4, 2, 9, 5, 0, 9, 5,\n",
       "        8, 3, 4, 4, 6, 4, 9, 0, 0, 3, 2, 4, 4, 5, 2, 7, 1, 6, 3, 1, 3, 1,\n",
       "        2, 0, 7, 2, 5, 0, 5, 2, 9, 2, 9, 7, 0, 1, 0, 1, 6, 3, 8, 8, 2, 7,\n",
       "        8, 3, 9, 7, 1, 3, 4, 6, 0, 6, 9, 6, 5, 1, 2, 9, 2, 5, 0, 6, 8, 8,\n",
       "        2, 4, 7, 6, 4, 7, 7, 9, 6, 5, 9, 2, 1, 6, 6, 6, 9, 0, 9, 5, 1, 8,\n",
       "        7, 2, 9, 4, 1, 6, 8, 8, 8, 9, 2, 4, 0, 5, 5, 0, 3, 2, 5, 4, 8, 4,\n",
       "        1, 2, 0, 7, 9, 7, 4, 1, 8, 0, 2, 4, 5, 1, 9, 6, 8, 2, 5, 6, 6, 5,\n",
       "        2, 5, 7, 6, 5, 0, 5, 2, 8, 3, 4, 8, 1, 4, 2, 4, 1, 0, 7, 3, 4, 8,\n",
       "        8, 9, 1, 2, 4, 4, 4, 1, 2, 4, 9, 1, 9, 2, 1, 6, 6, 4, 4, 9, 9, 1,\n",
       "        0, 6, 5, 9, 4, 5, 7, 0, 9, 5, 2, 7, 9, 5, 9, 9, 5, 0, 7, 9, 7, 6,\n",
       "        2, 5, 5, 8, 7, 8, 7, 6, 2, 2, 8, 5, 7, 1, 1, 1, 3, 0, 2, 3, 1, 7,\n",
       "        6, 2, 6, 9, 5, 3, 7, 9, 3, 8, 5, 0, 5, 3, 3, 6, 4, 9, 8, 9, 2, 1,\n",
       "        9, 9, 0, 8, 7, 1, 0, 1, 1, 4, 4, 0, 6, 1, 7, 0, 6, 5, 0, 8, 1, 9,\n",
       "        8, 9, 3, 2, 4, 4, 9, 3, 0, 1, 3, 4, 0, 0, 5, 4, 1, 9, 7, 8, 1, 6,\n",
       "        8, 7, 3, 2, 7, 9, 3, 7]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label이 무작위로 섞인 채 잘 분리 되었는지 확인\n",
    "y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47710e59",
   "metadata": {},
   "source": [
    "### (5) 다양한 모델로 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35cfdaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답이 있는 문제에 대해 학습하는 것이므로 지도학습\n",
    "#  입력받은 데이터를 특정 카테고리 중 하나로 분류하는 문제이므로 분류 학습에 해당함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "971c5ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 모듈 로드\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1b6438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def evaluate_classifier(y_test, y_pred, roc = False):\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred): .4f}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred, average = 'macro'): .4f}\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_pred, average = 'macro'): .4f}\")\n",
    "    print(f\"F_SCORE: {f1_score(y_test, y_pred, average = 'macro'): .4f}\")\n",
    "    if roc:\n",
    "        print(f\"ROC_AUC: {roc_auc_score(y_test, y_pred, average = 'macro', multi_class = 'ovr'): .4f}\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59736452",
   "metadata": {},
   "source": [
    "1. Decision Tree 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e02c2c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n"
     ]
    }
   ],
   "source": [
    "# 의사결정트리모델 import 후, 난수 초기값 15로 설정하여 모델을 변수에 할당\n",
    "decision_tree = DecisionTreeClassifier(random_state = 15)\n",
    "print(decision_tree._estimator_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5420ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=15)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=15)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(random_state=15)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 의사결정 트리모델로 트레인 데이터 학습!\n",
    "decision_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "708d83b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 4, 4, 1, 2, 6, 9, 2, 5, 2, 5, 6, 5, 6, 6, 2, 4, 6, 1, 5, 2, 5,\n",
       "       2, 6, 7, 5, 4, 3, 7, 6, 9, 0, 4, 6, 9, 7, 1, 8, 7, 9, 8, 0, 4, 9,\n",
       "       3, 8, 7, 4, 7, 2, 2, 9, 3, 1, 2, 8, 6, 7, 8, 4, 2, 9, 5, 0, 1, 5,\n",
       "       3, 3, 4, 4, 1, 4, 8, 0, 0, 3, 2, 4, 4, 5, 2, 7, 1, 6, 3, 1, 3, 1,\n",
       "       2, 2, 7, 5, 5, 0, 5, 2, 1, 2, 2, 7, 0, 1, 0, 1, 6, 3, 8, 8, 8, 7,\n",
       "       8, 3, 9, 7, 1, 1, 4, 6, 0, 6, 9, 6, 5, 1, 2, 5, 2, 7, 0, 6, 9, 8,\n",
       "       2, 6, 7, 6, 4, 3, 7, 2, 6, 5, 9, 2, 1, 6, 6, 6, 5, 0, 9, 5, 3, 8,\n",
       "       7, 8, 3, 4, 1, 6, 8, 8, 8, 9, 2, 4, 0, 5, 5, 0, 3, 2, 5, 4, 8, 4,\n",
       "       1, 2, 0, 7, 9, 7, 4, 3, 2, 0, 2, 4, 5, 4, 9, 2, 8, 2, 5, 6, 6, 5,\n",
       "       2, 5, 7, 6, 5, 0, 5, 2, 8, 3, 4, 8, 1, 4, 9, 4, 1, 0, 9, 3, 4, 8,\n",
       "       8, 9, 1, 2, 4, 4, 4, 1, 2, 4, 9, 1, 9, 2, 1, 6, 6, 4, 3, 9, 9, 1,\n",
       "       0, 6, 5, 9, 4, 5, 7, 0, 9, 5, 3, 7, 9, 5, 3, 9, 5, 8, 7, 1, 7, 6,\n",
       "       2, 5, 5, 8, 7, 2, 7, 6, 2, 2, 8, 2, 7, 1, 1, 6, 3, 0, 2, 3, 1, 7,\n",
       "       6, 2, 6, 9, 5, 3, 7, 9, 9, 1, 5, 0, 5, 3, 8, 6, 6, 9, 8, 9, 2, 2,\n",
       "       9, 9, 0, 8, 7, 1, 0, 8, 1, 4, 4, 0, 6, 1, 7, 8, 6, 5, 0, 8, 1, 9,\n",
       "       8, 9, 3, 2, 6, 4, 9, 3, 0, 1, 3, 7, 0, 0, 5, 9, 1, 9, 7, 8, 1, 6,\n",
       "       8, 7, 3, 2, 7, 9, 9, 7])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 데이터로 예측!\n",
    "# X_test데이터로 predict실행하면 모델이 예측한 y_pred를 얻음\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e8fea4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 4, 4, 1, 2, 6, 4, 2, 5, 1, 5, 6, 8, 6, 6, 6, 4, 6, 1, 3, 3, 5,\n",
       "       2, 6, 7, 5, 4, 3, 7, 3, 9, 0, 4, 6, 8, 7, 1, 8, 7, 9, 8, 0, 4, 9,\n",
       "       3, 8, 7, 6, 7, 2, 8, 9, 3, 1, 2, 8, 6, 4, 8, 4, 2, 9, 5, 0, 9, 5,\n",
       "       8, 3, 4, 4, 6, 4, 9, 0, 0, 3, 2, 4, 4, 5, 2, 7, 1, 6, 3, 1, 3, 1,\n",
       "       2, 0, 7, 2, 5, 0, 5, 2, 9, 2, 9, 7, 0, 1, 0, 1, 6, 3, 8, 8, 2, 7,\n",
       "       8, 3, 9, 7, 1, 3, 4, 6, 0, 6, 9, 6, 5, 1, 2, 9, 2, 5, 0, 6, 8, 8,\n",
       "       2, 4, 7, 6, 4, 7, 7, 9, 6, 5, 9, 2, 1, 6, 6, 6, 9, 0, 9, 5, 1, 8,\n",
       "       7, 2, 9, 4, 1, 6, 8, 8, 8, 9, 2, 4, 0, 5, 5, 0, 3, 2, 5, 4, 8, 4,\n",
       "       1, 2, 0, 7, 9, 7, 4, 1, 8, 0, 2, 4, 5, 1, 9, 6, 8, 2, 5, 6, 6, 5,\n",
       "       2, 5, 7, 6, 5, 0, 5, 2, 8, 3, 4, 8, 1, 4, 2, 4, 1, 0, 7, 3, 4, 8,\n",
       "       8, 9, 1, 2, 4, 4, 4, 1, 2, 4, 9, 1, 9, 2, 1, 6, 6, 4, 4, 9, 9, 1,\n",
       "       0, 6, 5, 9, 4, 5, 7, 0, 9, 5, 2, 7, 9, 5, 9, 9, 5, 0, 7, 9, 7, 6,\n",
       "       2, 5, 5, 8, 7, 8, 7, 6, 2, 2, 8, 5, 7, 1, 1, 1, 3, 0, 2, 3, 1, 7,\n",
       "       6, 2, 6, 9, 5, 3, 7, 9, 3, 8, 5, 0, 5, 3, 3, 6, 4, 9, 8, 9, 2, 1,\n",
       "       9, 9, 0, 8, 7, 1, 0, 1, 1, 4, 4, 0, 6, 1, 7, 0, 6, 5, 0, 8, 1, 9,\n",
       "       8, 9, 3, 2, 4, 4, 9, 3, 0, 1, 3, 4, 0, 0, 5, 4, 1, 9, 7, 8, 1, 6,\n",
       "       8, 7, 3, 2, 7, 9, 3, 7])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정답 데이터와 비교해서 얼마나 맞았는지 확인\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b6bd532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8444444444444444"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정답 y_test와 예측값 y_pred 비교하여 정확도 측정\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ece84d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95        31\n",
      "           1       0.84      0.82      0.83        38\n",
      "           2       0.73      0.87      0.80        38\n",
      "           3       0.71      0.74      0.73        27\n",
      "           4       0.94      0.80      0.87        41\n",
      "           5       0.87      0.94      0.90        35\n",
      "           6       0.87      0.89      0.88        38\n",
      "           7       0.91      0.94      0.93        34\n",
      "           8       0.79      0.77      0.78        35\n",
      "           9       0.80      0.77      0.79        43\n",
      "\n",
      "    accuracy                           0.84       360\n",
      "   macro avg       0.85      0.85      0.84       360\n",
      "weighted avg       0.85      0.84      0.85       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17539f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8444\n",
      "Precision:  0.8482\n",
      "Recall:  0.8451\n",
      "F_SCORE:  0.8450\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95        31\n",
      "           1       0.84      0.82      0.83        38\n",
      "           2       0.73      0.87      0.80        38\n",
      "           3       0.71      0.74      0.73        27\n",
      "           4       0.94      0.80      0.87        41\n",
      "           5       0.87      0.94      0.90        35\n",
      "           6       0.87      0.89      0.88        38\n",
      "           7       0.91      0.94      0.93        34\n",
      "           8       0.79      0.77      0.78        35\n",
      "           9       0.80      0.77      0.79        43\n",
      "\n",
      "    accuracy                           0.84       360\n",
      "   macro avg       0.85      0.85      0.84       360\n",
      "weighted avg       0.85      0.84      0.85       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_classifier(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269973b2",
   "metadata": {},
   "source": [
    "2. Random Forest 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b843b53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95        31\n",
      "           1       0.97      0.97      0.97        38\n",
      "           2       1.00      1.00      1.00        38\n",
      "           3       0.96      0.96      0.96        27\n",
      "           4       0.95      0.98      0.96        41\n",
      "           5       0.97      1.00      0.99        35\n",
      "           6       1.00      0.97      0.99        38\n",
      "           7       0.97      1.00      0.99        34\n",
      "           8       0.97      0.94      0.96        35\n",
      "           9       0.98      0.98      0.98        43\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.98      0.97      0.97       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=15)\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a3ca3f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.975"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a658c46",
   "metadata": {},
   "source": [
    "3. SVM 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79dc0684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm_model = svm.SVC()\n",
    "\n",
    "print(svm_model._estimator_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "434d924e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        31\n",
      "           1       0.95      1.00      0.97        38\n",
      "           2       1.00      1.00      1.00        38\n",
      "           3       0.96      0.96      0.96        27\n",
      "           4       0.98      0.98      0.98        41\n",
      "           5       1.00      1.00      1.00        35\n",
      "           6       1.00      1.00      1.00        38\n",
      "           7       1.00      1.00      1.00        34\n",
      "           8       0.97      0.94      0.96        35\n",
      "           9       0.98      0.98      0.98        43\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca1e6e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9833333333333333"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e98778c",
   "metadata": {},
   "source": [
    "4. SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "01c7b86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_model = SGDClassifier()\n",
    "\n",
    "print(sgd_model._estimator_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5639a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        31\n",
      "           1       0.88      0.97      0.93        38\n",
      "           2       1.00      0.97      0.99        38\n",
      "           3       0.93      0.96      0.95        27\n",
      "           4       0.95      0.98      0.96        41\n",
      "           5       0.97      1.00      0.99        35\n",
      "           6       1.00      0.97      0.99        38\n",
      "           7       0.94      1.00      0.97        34\n",
      "           8       0.86      0.89      0.87        35\n",
      "           9       1.00      0.86      0.92        43\n",
      "\n",
      "    accuracy                           0.95       360\n",
      "   macro avg       0.95      0.95      0.95       360\n",
      "weighted avg       0.96      0.95      0.95       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf3ec88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9527777777777777"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a21f43",
   "metadata": {},
   "source": [
    "5. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e19cbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "print(logistic_model._estimator_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1b4cdbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        31\n",
      "           1       0.95      0.97      0.96        38\n",
      "           2       1.00      0.97      0.99        38\n",
      "           3       0.96      0.93      0.94        27\n",
      "           4       0.98      1.00      0.99        41\n",
      "           5       0.97      0.97      0.97        35\n",
      "           6       1.00      0.97      0.99        38\n",
      "           7       1.00      1.00      1.00        34\n",
      "           8       0.92      0.97      0.94        35\n",
      "           9       0.98      0.95      0.96        43\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.98      0.97      0.97       360\n",
      "weighted avg       0.98      0.97      0.98       360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SJang\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f08b0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.975"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b37467c",
   "metadata": {},
   "source": [
    "# (6) 모델 평가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32259cb4",
   "metadata": {},
   "source": [
    "#### 1) Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b7b816",
   "metadata": {},
   "source": [
    "* 정확히 예측한 수/ 전체 샘플 수\n",
    "\n",
    "* 단점 예시) 내일 서울 에 시간단 1m 이상의 눈이 내릴지 여부를 예측한다고 가정. 무조건 Negative를 예측하면 이 분류기는 99.9 % 의 정확도를 나타냄. 그정도 눈이 내리는 날은 거의 없으니까. 즉, 이 분류기는 정답을 TN만 잔뜩 맞히고 TP는 하나도 발견하지 못한것. \n",
    "\n",
    "* 이렇게 실제 데이터에 Negative 비율이 너무 높아서 희박한 가능성으로 발생할 상황에 대해 제대로 된 분류를 해주는지 평가해줄 지표는 Recall 이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c04b11",
   "metadata": {},
   "source": [
    "#### 2) Recall (재현율)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b8b0eb",
   "metadata": {},
   "source": [
    "* 양성으로 분류된 샘플 수 / 전체 양성 샘플 수\n",
    "* 실제 True인 것 중에서 모델이 True로 예측한 비율. \n",
    "* 애초에 True가 발생하는 확률이 적을 때 사용하면 좋음.\n",
    "\n",
    "* 예시) 시간당 1m 이상의 눈이 내릴지 예측하는 과제에 적절. 실제로 눈이 내린 날짜 중 몇 개나 맞히는지 확인할 수 있으므로. 만약 언제나 False로 예측하는 분류기가 있다면 정확도는 99%를 넘기겠지만, TP를 찾을 수 없으니 recall이 0이 됨.\n",
    "\n",
    "* 단점 예시) 시간당 적설량 1m 이상이 될지 분류하는 과제에서 언제나 True만 답하는 분류기가 있다고 가정. 정확도는 낮지만, 눈이 많이 온 날에 대해서만큼은 저확하게 맞힐 수 있기 때문에 recall은 1이 됨. 이 또한 말이 안되는 지표임.\n",
    "\n",
    "* 이럴때 해당 알고리즘에 결함이 있음을 나타내는 지표는 precision임."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cf0919",
   "metadata": {},
   "source": [
    "#### 3) Precision (정밀도)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82e5fb2",
   "metadata": {},
   "source": [
    "* 진짜 양성 샘플 수/양성으로 예측된 샘플 수\n",
    "* 모델이 True라고 분류한 것 중 실제 True인 것의 비율\n",
    "* 분류기가 눈이 많이 내릴거라고 예측한 날 중, 실제로 눈이 많이 내린 날의 비율\n",
    "* Recall과 Precision은 서로 상충하는 개념"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85b84f3",
   "metadata": {},
   "source": [
    "판별된 숫자가 어디에 어떻게 쓰이느냐에 따라 판별요소들의 중요도가 달라지는 것 같다. \n",
    " 예) 주차장을 들어가는 자동차의 번호표를 읽을 때, 경찰이 범인의 차번호를 조회할때 등등\n",
    "\n",
    "상황들을 고려해봤을 때, 정밀도와 재현율을 적절히 고려한 f1_score모델이 적합하다고 생각된다. 때문에 숫자판별 프로젝트에서는 SVM 모델이 적합한 것으로 보인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0955cf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9750\n",
      "Precision:  0.9753\n",
      "Recall:  0.9743\n",
      "F_SCORE:  0.9746\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        31\n",
      "           1       0.95      0.97      0.96        38\n",
      "           2       1.00      0.97      0.99        38\n",
      "           3       0.96      0.93      0.94        27\n",
      "           4       0.98      1.00      0.99        41\n",
      "           5       0.97      0.97      0.97        35\n",
      "           6       1.00      0.97      0.99        38\n",
      "           7       1.00      1.00      1.00        34\n",
      "           8       0.92      0.97      0.94        35\n",
      "           9       0.98      0.95      0.96        43\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.98      0.97      0.97       360\n",
      "weighted avg       0.98      0.97      0.98       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_classifier(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4607ffec",
   "metadata": {},
   "source": [
    "# 프로젝트 (2) load_wine : 와인 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3d197b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b3b999ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine = load_wine()\n",
    "wine.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "caf59aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
       "        1.065e+03],\n",
       "       [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
       "        1.050e+03],\n",
       "       [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
       "        1.185e+03],\n",
       "       ...,\n",
       "       [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
       "        8.350e+02],\n",
       "       [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
       "        8.400e+02],\n",
       "       [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
       "        5.600e+02]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "80dcfed5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "91791d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['class_0', 'class_1', 'class_2'], dtype='<U7')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.target_names\n",
    "# target의 이름이 class-0, 1, 2로 되어있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3b58f0a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alcohol',\n",
       " 'malic_acid',\n",
       " 'ash',\n",
       " 'alcalinity_of_ash',\n",
       " 'magnesium',\n",
       " 'total_phenols',\n",
       " 'flavanoids',\n",
       " 'nonflavanoid_phenols',\n",
       " 'proanthocyanins',\n",
       " 'color_intensity',\n",
       " 'hue',\n",
       " 'od280/od315_of_diluted_wines',\n",
       " 'proline']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eb87fe0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.. _wine_dataset:\\n\\nWine recognition dataset\\n------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 178\\n    :Number of Attributes: 13 numeric, predictive attributes and the class\\n    :Attribute Information:\\n \\t\\t- Alcohol\\n \\t\\t- Malic acid\\n \\t\\t- Ash\\n\\t\\t- Alcalinity of ash  \\n \\t\\t- Magnesium\\n\\t\\t- Total phenols\\n \\t\\t- Flavanoids\\n \\t\\t- Nonflavanoid phenols\\n \\t\\t- Proanthocyanins\\n\\t\\t- Color intensity\\n \\t\\t- Hue\\n \\t\\t- OD280/OD315 of diluted wines\\n \\t\\t- Proline\\n\\n    - class:\\n            - class_0\\n            - class_1\\n            - class_2\\n\\t\\t\\n    :Summary Statistics:\\n    \\n    ============================= ==== ===== ======= =====\\n                                   Min   Max   Mean     SD\\n    ============================= ==== ===== ======= =====\\n    Alcohol:                      11.0  14.8    13.0   0.8\\n    Malic Acid:                   0.74  5.80    2.34  1.12\\n    Ash:                          1.36  3.23    2.36  0.27\\n    Alcalinity of Ash:            10.6  30.0    19.5   3.3\\n    Magnesium:                    70.0 162.0    99.7  14.3\\n    Total Phenols:                0.98  3.88    2.29  0.63\\n    Flavanoids:                   0.34  5.08    2.03  1.00\\n    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\\n    Proanthocyanins:              0.41  3.58    1.59  0.57\\n    Colour Intensity:              1.3  13.0     5.1   2.3\\n    Hue:                          0.48  1.71    0.96  0.23\\n    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\\n    Proline:                       278  1680     746   315\\n    ============================= ==== ===== ======= =====\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML Wine recognition datasets.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\\n\\nThe data is the results of a chemical analysis of wines grown in the same\\nregion in Italy by three different cultivators. There are thirteen different\\nmeasurements taken for different constituents found in the three types of\\nwine.\\n\\nOriginal Owners: \\n\\nForina, M. et al, PARVUS - \\nAn Extendible Package for Data Exploration, Classification and Correlation. \\nInstitute of Pharmaceutical and Food Analysis and Technologies,\\nVia Brigata Salerno, 16147 Genoa, Italy.\\n\\nCitation:\\n\\nLichman, M. (2013). UCI Machine Learning Repository\\n[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\\nSchool of Information and Computer Science. \\n\\n.. topic:: References\\n\\n  (1) S. Aeberhard, D. Coomans and O. de Vel, \\n  Comparison of Classifiers in High Dimensional Settings, \\n  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Technometrics). \\n\\n  The data was used with many others for comparing various \\n  classifiers. The classes are separable, though only RDA \\n  has achieved 100% correct classification. \\n  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \\n  (All results using the leave-one-out technique) \\n\\n  (2) S. Aeberhard, D. Coomans and O. de Vel, \\n  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \\n  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Journal of Chemometrics).\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c7af75ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_data = wine.data\n",
    "print(wine_data.shape)\n",
    "type(wine_data)\n",
    "# 178개의 데이터가 각각 13개의 feature정보를 담고 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "61a12a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_label = wine.target\n",
    "\n",
    "print(wine_label.shape)\n",
    "wine_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9f46ae",
   "metadata": {},
   "source": [
    "### data frame 만들기_data, feature_name, label 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c2095c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  \n",
       "0                            3.92   1065.0  \n",
       "1                            3.40   1050.0  \n",
       "2                            3.17   1185.0  \n",
       "3                            3.45   1480.0  \n",
       "4                            2.93    735.0  \n",
       "..                            ...      ...  \n",
       "173                          1.74    740.0  \n",
       "174                          1.56    750.0  \n",
       "175                          1.56    835.0  \n",
       "176                          1.62    840.0  \n",
       "177                          1.60    560.0  \n",
       "\n",
       "[178 rows x 13 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df = pd.DataFrame(data = wine_data, columns=wine.feature_names)\n",
    "wine_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "114c3025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  label  \n",
       "0                            3.92   1065.0      0  \n",
       "1                            3.40   1050.0      0  \n",
       "2                            3.17   1185.0      0  \n",
       "3                            3.45   1480.0      0  \n",
       "4                            2.93    735.0      0  \n",
       "..                            ...      ...    ...  \n",
       "173                          1.74    740.0      2  \n",
       "174                          1.56    750.0      2  \n",
       "175                          1.56    835.0      2  \n",
       "176                          1.62    840.0      2  \n",
       "177                          1.60    560.0      2  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label을 df 컬럼에 추가\n",
    "wine_df[\"label\"] = wine.target\n",
    "wine_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e66f322",
   "metadata": {},
   "source": [
    "### 학습 데이터와 테스트 데이터 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "93d30820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train 개수:  142 ,x_test 개수:  36\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(wine_data, wine_label, test_size=0.2, random_state=7)\n",
    "\n",
    "print('x_train 개수: ', len(x_train), ',x_test 개수: ', len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6f7a4a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((142, 13), (36, 13))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "16788483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((142,), (36,))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "68ccf0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 2, 0, 2, 0, 1, 2, 2, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "        2, 0, 2, 1, 2, 0, 2, 1, 1, 1, 0, 1, 0, 0, 2, 0, 2, 1, 1, 2, 1, 0,\n",
       "        1, 1, 1, 1, 0, 0, 0, 1, 1, 2, 1, 0, 1, 2, 0, 1, 0, 2, 1, 0, 0, 0,\n",
       "        0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 2, 2, 0, 0, 0, 2, 0, 0, 1, 2, 1, 1,\n",
       "        0, 0, 2, 0, 2, 2, 2, 1, 2, 1, 2, 1, 0, 0, 2, 1, 2, 1, 1, 0, 1, 2,\n",
       "        1, 2, 0, 0, 2, 0, 1, 2, 0, 1, 0, 0, 0, 0, 1, 0, 2, 1, 1, 2, 0, 1,\n",
       "        1, 1, 0, 2, 1, 1, 2, 1, 0, 2]),\n",
       " array([2, 0, 2, 2, 1, 2, 1, 0, 1, 2, 0, 1, 2, 1, 1, 1, 1, 2, 0, 0, 1, 1,\n",
       "        1, 1, 0, 2, 1, 2, 2, 2, 1, 0, 2, 1, 1, 1]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 랜덤하게 잘 섞여서 나뉘어졌는지 확인\n",
    "y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7df0d6c",
   "metadata": {},
   "source": [
    "### 학습시키기 (지도학습, 분류)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cde521",
   "metadata": {},
   "source": [
    "1. Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "10e7d16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 2 2 1 2 1 0 1 1 0 1 1 1 1 1 1 2 0 0 0 1 1 1 0 2 1 2 2 2 1 0 2 1 1 1]\n",
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       0.89      0.94      0.91        17\n",
      "           2       1.00      0.83      0.91        12\n",
      "\n",
      "    accuracy                           0.92        36\n",
      "   macro avg       0.92      0.92      0.92        36\n",
      "weighted avg       0.92      0.92      0.92        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree.fit(x_train, y_train)\n",
    "y_pred = decision_tree.predict(x_test)\n",
    "print(y_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104a5a06",
   "metadata": {},
   "source": [
    "2. Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e5ab4c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 0 1 1 2 1 1 1 2 1 1 1 2]\n",
      "0.6111111111111112\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86         7\n",
      "           1       0.58      0.88      0.70        17\n",
      "           2       0.33      0.08      0.13        12\n",
      "\n",
      "    accuracy                           0.61        36\n",
      "   macro avg       0.59      0.61      0.56        36\n",
      "weighted avg       0.55      0.61      0.54        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_model = svm.SVC()\n",
    "svm_model.fit(x_train, y_train)\n",
    "y_pred = svm_model.predict(x_test)\n",
    "print(y_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3143de",
   "metadata": {},
   "source": [
    "3. Stochastic Gradient Descent Classifier (SGDClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bb3b8e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 2 1 2 1 0 2 2 0 1 2 2 1 1 0 2 0 0 0 2 1 1 0 2 1 0 1 0 1 0 1 1 1 2]\n",
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      1.00      0.70         7\n",
      "           1       0.85      0.65      0.73        17\n",
      "           2       0.60      0.50      0.55        12\n",
      "\n",
      "    accuracy                           0.67        36\n",
      "   macro avg       0.66      0.72      0.66        36\n",
      "weighted avg       0.70      0.67      0.66        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd_model = SGDClassifier()\n",
    "sgd_model.fit(x_train, y_train)\n",
    "y_pred = sgd_model.predict(x_test)\n",
    "print(y_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22760019",
   "metadata": {},
   "source": [
    "4. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f7220c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 2 2 1 2 1 0 1 2 0 1 2 1 1 1 1 2 0 0 1 1 1 1 0 2 1 2 2 2 1 1 2 1 1 1]\n",
      "0.9722222222222222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92         7\n",
      "           1       0.94      1.00      0.97        17\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.95      0.96        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SJang\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logistic_model.fit(x_train, y_train)\n",
    "y_pred = logistic_model.predict(x_test)\n",
    "print(y_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49d011d",
   "metadata": {},
   "source": [
    "5. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a2ca64cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 2 2 1 2 1 0 1 2 0 1 2 1 1 1 1 2 0 0 1 1 1 1 0 2 1 2 2 2 1 0 2 1 1 1]\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00        17\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest.fit(x_train, y_train)\n",
    "y_pred = random_forest.predict(x_test)\n",
    "print(y_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8890c995",
   "metadata": {},
   "source": [
    "### 모델 평가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7ad14f",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5775446",
   "metadata": {},
   "source": [
    "f1-score는 정밀도와 재현율을 조합하여 만든 지표로, 분류 모델의 최종 성능 평가 지표로 적합하다고 생각한다.\n",
    "\n",
    "Random Forest 모델이 모든 평가지표로 봤을 때 가장 높은 값을 갖는다(..?) 무튼 f1-score가 가장 높은 Random Forest모델이 와인 분류용 모델로 적합하다고 여겨진다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcf6299",
   "metadata": {},
   "source": [
    "# 프로젝트 (3) breast_cancer : 유방암 여부 진단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2437b191",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e016f55",
   "metadata": {},
   "source": [
    "### 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "74ce1ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer = load_breast_cancer()\n",
    "cancer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5e445433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.799e+01 1.038e+01 1.228e+02 ... 2.654e-01 4.601e-01 1.189e-01]\n",
      " [2.057e+01 1.777e+01 1.329e+02 ... 1.860e-01 2.750e-01 8.902e-02]\n",
      " [1.969e+01 2.125e+01 1.300e+02 ... 2.430e-01 3.613e-01 8.758e-02]\n",
      " ...\n",
      " [1.660e+01 2.808e+01 1.083e+02 ... 1.418e-01 2.218e-01 7.820e-02]\n",
      " [2.060e+01 2.933e+01 1.401e+02 ... 2.650e-01 4.087e-01 1.240e-01]\n",
      " [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 2.871e-01 7.039e-02]]\n",
      "(569, 30)\n"
     ]
    }
   ],
   "source": [
    "print(cancer.data)\n",
    "cancer_data = cancer.data\n",
    "print(cancer.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "93cd084c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n",
      "(569,)\n"
     ]
    }
   ],
   "source": [
    "print(cancer.target)\n",
    "cancer_label = cancer.target\n",
    "print(cancer_label.shape)\n",
    "\n",
    "# 기다 아니다 1, 0 로 분류됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "37e35c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.target_names\n",
    "\n",
    "# 1이면 malignant (악성종양)\n",
    "# 0이면 benign (양성종양)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "133e5444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.feature_names\n",
    "\n",
    "#  DataFrame의 컬럼으로 지정하면 좋을 듯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a2ba4d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'breast_cancer.csv'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3e528dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sklearn.datasets.data'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.data_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dd17b56c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "0                   0.07871  ...        25.380          17.33   \n",
       "1                   0.05667  ...        24.990          23.41   \n",
       "2                   0.05999  ...        23.570          25.53   \n",
       "3                   0.09744  ...        14.910          26.50   \n",
       "4                   0.05883  ...        22.540          16.67   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                 0.05623  ...        25.450          26.40   \n",
       "565                 0.05533  ...        23.690          38.25   \n",
       "566                 0.05648  ...        18.980          34.12   \n",
       "567                 0.07016  ...        25.740          39.42   \n",
       "568                 0.05884  ...         9.456          30.37   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "0             184.60      2019.0           0.16220            0.66560   \n",
       "1             158.80      1956.0           0.12380            0.18660   \n",
       "2             152.50      1709.0           0.14440            0.42450   \n",
       "3              98.87       567.7           0.20980            0.86630   \n",
       "4             152.20      1575.0           0.13740            0.20500   \n",
       "..               ...         ...               ...                ...   \n",
       "564           166.10      2027.0           0.14100            0.21130   \n",
       "565           155.00      1731.0           0.11660            0.19220   \n",
       "566           126.70      1124.0           0.11390            0.30940   \n",
       "567           184.60      1821.0           0.16500            0.86810   \n",
       "568            59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.7119                0.2654          0.4601   \n",
       "1             0.2416                0.1860          0.2750   \n",
       "2             0.4504                0.2430          0.3613   \n",
       "3             0.6869                0.2575          0.6638   \n",
       "4             0.4000                0.1625          0.2364   \n",
       "..               ...                   ...             ...   \n",
       "564           0.4107                0.2216          0.2060   \n",
       "565           0.3215                0.1628          0.2572   \n",
       "566           0.3403                0.1418          0.2218   \n",
       "567           0.9387                0.2650          0.4087   \n",
       "568           0.0000                0.0000          0.2871   \n",
       "\n",
       "     worst fractal dimension  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "567                  0.12400  \n",
       "568                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df = pd.DataFrame(data=cancer_data, columns=cancer.feature_names)\n",
    "cancer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "41471b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target 컬럼에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "11fd0be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  label  \n",
       "0                  0.2654          0.4601                  0.11890      0  \n",
       "1                  0.1860          0.2750                  0.08902      0  \n",
       "2                  0.2430          0.3613                  0.08758      0  \n",
       "3                  0.2575          0.6638                  0.17300      0  \n",
       "4                  0.1625          0.2364                  0.07678      0  \n",
       "..                    ...             ...                      ...    ...  \n",
       "564                0.2216          0.2060                  0.07115      0  \n",
       "565                0.1628          0.2572                  0.06637      0  \n",
       "566                0.1418          0.2218                  0.07820      0  \n",
       "567                0.2650          0.4087                  0.12400      0  \n",
       "568                0.0000          0.2871                  0.07039      1  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df[\"label\"] = cancer.target\n",
    "cancer_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22692e33",
   "metadata": {},
   "source": [
    "### 데이터셋 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "89a40869",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(cancer_data, cancer_label, test_size = 0.2, random_state = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "99a69245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((455, 30), (114, 30))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e5d779f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((455,), (114,))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "65c74542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "        0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "        0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "        1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n",
       "        0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "        1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "        0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "        0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1,\n",
       "        1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "        1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "        1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "        1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1]),\n",
       " array([1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "        0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "        1, 0, 0, 1]))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5496b027",
   "metadata": {},
   "source": [
    "### 모델 학습 시작! (지도학습, 분류)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b61ebe0",
   "metadata": {},
   "source": [
    "1. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "64b6c1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 0 0 0 0 0 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1\n",
      " 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 0 1 1 1 1 0 1 1 1 0 1\n",
      " 0 0 1]\n",
      "0.9473684210526315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.92        39\n",
      "           1       0.94      0.99      0.96        75\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree.fit(x_train, y_train)\n",
    "y_pred = decision_tree.predict(x_test)\n",
    "print(y_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0080077",
   "metadata": {},
   "source": [
    "2. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b10629f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 0 1 0 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1\n",
      " 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 0 1 1 0 1 1 1 1 0 1 1 1 0 1\n",
      " 0 0 1]\n",
      "0.9298245614035088\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.85      0.89        39\n",
      "           1       0.92      0.97      0.95        75\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest.fit(x_train, y_train)\n",
    "y_pred = random_forest.predict(x_test)\n",
    "print(y_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa99ef0b",
   "metadata": {},
   "source": [
    " 3. svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d50efa69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 0 1 0 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1\n",
      " 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1\n",
      " 0 0 1]\n",
      "0.868421052631579\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.67      0.78        39\n",
      "           1       0.85      0.97      0.91        75\n",
      "\n",
      "    accuracy                           0.87       114\n",
      "   macro avg       0.89      0.82      0.84       114\n",
      "weighted avg       0.88      0.87      0.86       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_model.fit(x_train, y_train)\n",
    "y_pred = svm_model.predict(x_test)\n",
    "print(y_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894ceda9",
   "metadata": {},
   "source": [
    "4. SGDClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6c1f0cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1\n",
      " 0 0 1]\n",
      "0.8245614035087719\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.51      0.67        39\n",
      "           1       0.80      0.99      0.88        75\n",
      "\n",
      "    accuracy                           0.82       114\n",
      "   macro avg       0.87      0.75      0.77       114\n",
      "weighted avg       0.85      0.82      0.81       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd_model.fit(x_train, y_train)\n",
    "y_pred = sgd_model.predict(x_test)\n",
    "print(y_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e14f9e",
   "metadata": {},
   "source": [
    "5. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3bfb7e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 1\n",
      " 0 1 1 0 1 0 0 0 0 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1\n",
      " 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 1 0 1 1 1 0 0 1 1 0 0\n",
      " 0 0 1]\n",
      "0.8947368421052632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85        39\n",
      "           1       0.92      0.92      0.92        75\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.88      0.88      0.88       114\n",
      "weighted avg       0.89      0.89      0.89       114\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SJang\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logistic_model.fit(x_train, y_train)\n",
    "y_pred = logistic_model.predict(x_test)\n",
    "print(y_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9deb535d",
   "metadata": {},
   "source": [
    "### 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f11964e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8830769230769231\n"
     ]
    }
   ],
   "source": [
    "# roc_auc_score ()\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90de4d94",
   "metadata": {},
   "source": [
    "암에 걸렸는지 안걸렸는지 분류하는 모델의 경우, 실제 암인 사람들을 놓치지 않고\n",
    "파악하는게 중요하므로 재현율 (Recall)이 더 중요한 평가 지표라고 생각한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1be5023",
   "metadata": {},
   "source": [
    "가장 높은 Recall 값을 갖는 모델은 Decision tree 모델이므로,\n",
    "암진단에 가장 적합한 모델은 Decision Tree 모델이라고 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca468ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfedeb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf724d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eb4b75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
